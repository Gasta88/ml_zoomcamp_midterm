{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean_data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2,random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25,random_state=1)\n",
    "\n",
    "df_train.reset_index(drop=True)\n",
    "df_val.reset_index(drop=True)\n",
    "df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train[\"amount\"].values\n",
    "y_val = df_val[\"amount\"].values\n",
    "y_test = df_test[\"amount\"].values\n",
    "\n",
    "del df_train[\"amount\"]\n",
    "del df_val[\"amount\"]\n",
    "del df_test[\"amount\"]\n",
    "\n",
    "cat = [  \"provider\", \"countrycode\", \"market\"]\n",
    "num = [\"usercurrencyamount\", \"coins\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(df_train[cat + num].to_dict(orient=\"records\"))\n",
    "X_val = dv.transform(df_val[cat + num].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "print(f\"Accuracy: {mean_squared_error(y_val,y_pred)}\")\n",
    "print(f\"R^2: {r2_score(y_val,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alphas = [0, 0.01, 0.1, 1, 10]\n",
    "solvers = [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "\n",
    "scores = []\n",
    "for s in solvers:\n",
    "    for a in alphas:\n",
    "        lr = Ridge(alpha=a, solver=s)\n",
    "        lr.fit(X_train,y_train)\n",
    "        y_pred = lr.predict(X_val)\n",
    "        scores.append((s,a,mean_squared_error(y_val,y_pred),r2_score(y_val,y_pred)))\n",
    "df_scores = pd.DataFrame(scores,columns=[\"solver\",\"alpha\",\"score\",\"r2\"])\n",
    "df_scores.sort_values(by=[\"score\",\"r2\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in solvers:\n",
    "    if s in [\"svd\", \"cholesky\", \"lsqr\"]:\n",
    "        plt.plot(df_scores[df_scores[\"solver\"] == s][\"alpha\"],df_scores[df_scores[\"solver\"] == s][\"score\"], label=s)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Best combo for Ridge seems solver=\"svd\", alpha=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "max_depths = [1, 2, 3, 4, 5, 6, 7, None]\n",
    "min_sample_leafs = [1,2, 5, 10,20]\n",
    "\n",
    "scores = []\n",
    "for s in min_sample_leafs:\n",
    "    for d in [1, 2, 3, 4, 5, 6, 7, None]:\n",
    "        dt = DecisionTreeRegressor(max_depth=d, random_state=1, min_samples_leaf=s)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred = dt.predict(X_val)\n",
    "        scores.append((d,s,mean_squared_error(y_val,y_pred),r2_score(y_val,y_pred)))\n",
    "df_scores = pd.DataFrame(scores,columns=[\"max_depth\",\"min_samples_leaf\",\"score\",\"r2\"])\n",
    "df_scores.sort_values(by=[\"score\",\"r2\"], ascending=True).head(10)\n",
    "\n",
    "# Best combo for DecisionTreeRegressor seems max_depth=7, min_samples_leaf=1\n",
    "# Leaving max_depth=None will cause overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "scores = []\n",
    "for n in range(10, 201, 10):\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    scores.append((n, mean_squared_error(y_val, y_pred), r2_score(y_val, y_pred)))\n",
    "df_scores = pd.DataFrame(scores, columns=['n_estimators', 'score', 'r2'])\n",
    "df_scores.sort_values(by=[\"score\",\"r2\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_scores[\"n_estimators\"],df_scores[\"score\"])\n",
    "\n",
    "# Best performance starts around n_estimators=110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "max_depths = [1, 2, 3, 4, 5, 6, 7, None]\n",
    "n_estimators = list(range(100,180,10))\n",
    "\n",
    "for d in max_depths:\n",
    "    for n in n_estimators:\n",
    "        rf = RandomForestRegressor(n_estimators=n,max_depth=d, random_state=1, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        scores.append((n, d, mean_squared_error(y_val, y_pred), r2_score(y_val, y_pred)))\n",
    "df_scores = pd.DataFrame(scores, columns=['n_estimators','max_depth', 'score', 'r2'])\n",
    "df_scores.sort_values(by=[\"score\",\"r2\"], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [5,6,7]:\n",
    "    plt.plot(df_scores[df_scores[\"max_depth\"]==d][\"n_estimators\"],df_scores[df_scores[\"max_depth\"]==d][\"score\"], label=f\"max_depth={d}\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Best performance starts around n_estimators=110 with a max_depth=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "scores = {}\n",
    "\n",
    "def parse_xgboost_output(s):\n",
    "    lines = s.strip().split('\\n')\n",
    "    eval_data = []\n",
    "    for line in lines:\n",
    "        num_iter, train_score, val_score = line.split('\\t')\n",
    "        num_iter = int(num_iter.strip('[]'))\n",
    "        train_score = float(train_score.split(':')[1])\n",
    "        val_score = float(val_score.split(':')[1])\n",
    "        eval_data.append((num_iter, train_score, val_score))\n",
    "\n",
    "    df_eval = pd.DataFrame(eval_data, columns=['tree', 'train_score', 'val_score'])\n",
    "    return df_eval\n",
    "\n",
    "features = dv.get_feature_names_out().tolist()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 1.0,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=200, evals=watchlist, verbose_eval=5)\n",
    "key = f'eta={str(xgb_params[\"eta\"])}'\n",
    "scores[key] = parse_xgboost_output(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, df in scores.items():\n",
    "    plt.plot(df.tree, df.val_score, label=k)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=200, evals=watchlist, verbose_eval=5)\n",
    "key = f'max_depth={str(xgb_params[\"max_depth\"])}'\n",
    "scores[key] = parse_xgboost_output(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, df in scores.items():\n",
    "    plt.plot(df.tree, df.val_score, label=k)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 10,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=200, evals=watchlist, verbose_eval=5)\n",
    "key = f'min_child_weight={str(xgb_params[\"min_child_weight\"])}'\n",
    "scores[key] = parse_xgboost_output(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, df in scores.items():\n",
    "    plt.plot(df.tree, df.val_score, label=k)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best models:\n",
    "\n",
    "- RandomForestRegressor with *n_estimators=110* and *max_depth=7*\n",
    "- XGBoost with following settings:\n",
    "  \n",
    "  ```python\n",
    "  xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 10,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train.reset_index(drop=True)\n",
    "\n",
    "y_full_train = df_full_train[\"amount\"].values\n",
    "\n",
    "del df_full_train[\"amount\"]\n",
    "\n",
    "\n",
    "X_full_train = dv.fit_transform(df_full_train[cat + num].to_dict(orient=\"records\"))\n",
    "X_test = dv.transform(df_test[cat + num].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=110, max_depth=7, random_state=1)\n",
    "rf.fit(X_full_train, y_full_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dv.get_feature_names_out().tolist()\n",
    "dfulltrain = xgb.DMatrix(X_full_train, label=y_full_train, feature_names=features)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=features)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 10,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1\n",
    "}\n",
    "model = xgb.train(xgb_params, dfulltrain, num_boost_round=200)\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random forest as pickle\n",
    "import pickle\n",
    "\n",
    "with open('../model/rf.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, rf), f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
